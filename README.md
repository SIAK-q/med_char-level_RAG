# Character-level Tokenization for Chinese Medical Language Models

本项目旨在探索中文医学场景下的字符级编码方法，以提升语言模型在同音字、形似字以及常见错别字输入下的鲁棒性。我们通过自底向上的字符级表示学习，结合针对医学术语的细粒度特征工程，构建能够在真实问答和信息检索任务中保持稳定表现的语言模型。

## 项目目标
- **构建字符级嵌入表示**：研究多种字符级 tokenization 策略，包括 Unicode 编码、部首/结构拆分、字形描绘等方式，为医学文本提供更加细致的表示。
- **增强同音/形似/错别字鲁棒性**：设计负样本生成与数据增强方案，针对发音相近、形状相似及常见拼写错误的汉字，提升模型的判别能力。
- **评估流程（RAG 作为验证管线）**：虽然 Retrieval-Augmented Generation (RAG) 并非重点，但我们将其用作评估模型鲁棒性的流程，确保字符级改进能够在问答/检索任务中体现效果。

## 研究路线
1. **文献调研与基线实现**
   - 收集中文字符级 tokenization 的相关研究，包括医学和通用领域。
   - 选取现有中文预训练模型（如 BERT、RoBERTa、Chinese-LLaMA 等）作为对比基线。
2. **字符级编码方案设计**
   - 设计多套编码方式（拼音映射、部首拆解、结构图编码等）。
   - 实现字符级嵌入层，比较不同方案在表示质量和计算成本上的差异。
3. **鲁棒性数据构建与训练策略**
   - 通过规则生成和人工标注构建同音字、形似字、错别字数据集。
   - 探索对比学习、对抗训练等策略，以强化模型对扰动字符的敏感度。
4. **RAG 流程验证**
   - 将优化后的字符级模型接入 RAG 流程作为编码器。
   - 评估在医学问答、文献检索等任务中的表现，并与基线进行对比。

## 当前仓库结构
- `data_process1.0.ipynb`：初步的数据处理实验记录。
- `dataset_modelClass.ipynb`：数据集与模型类别设计草稿。
- `main.ipynb`：主实验流水线的初步搭建。

## 下一步计划
- 梳理 notebook 内容，提炼可复用的脚本与模块。
- 搭建字符级 tokenization 原型，并与现有分词策略进行对比实验。
- 设计鲁棒性评测集，涵盖同音字、形似字以及错别字场景。

## 参考资料
- 中文字符级表示学习与 tokenization 相关论文。
- 医学问答与检索场景的公开数据集（如 CMedQA、CHIP 等）。
- RAG 架构在中文场景下的应用案例。
