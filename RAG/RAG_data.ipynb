{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb8b5a4-26aa-40e8-a38a-8c2a4bd7527b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 6 个CSV文件，开始加载...\n",
      "总计 433,567 条原始问答记录。\n",
      "数据清洗完成，剩余 401,463 条有效样本，125 个科室。\n",
      "已通过分层抽样划分出 10000 条测试样本。\n",
      "测试集已成功保存到: /root/RAG/test_data_10k.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 配置 ===\n",
    "DATA_ROOT_PATH = '../autodl-tmp/Data_数据/'\n",
    "TEST_SET_SIZE = 10000\n",
    "OUTPUT_FILENAME = '/root/RAG/test_data_10k.json'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def read_csv_force(path):\n",
    "    \"\"\"鲁棒读取CSV，忽略坏字符\"\"\"\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            raw = f.read()\n",
    "        # 尝试多种常见编码\n",
    "        for enc in [\"utf-8\", \"utf-8-sig\", \"gb18030\", \"gbk\", \"ISO-8859-1\"]:\n",
    "            try:\n",
    "                text = raw.decode(enc, errors=\"ignore\")\n",
    "                from io import StringIO\n",
    "                return pd.read_csv(StringIO(text), sep=None, engine=\"python\", on_bad_lines=\"skip\")\n",
    "            except Exception:\n",
    "                continue\n",
    "        return pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# === 主逻辑 ===\n",
    "file_paths = glob.glob(os.path.join(DATA_ROOT_PATH, '**', '*.csv'), recursive=True)\n",
    "if not file_paths:\n",
    "    raise FileNotFoundError(f\"路径 {DATA_ROOT_PATH} 下没有找到任何 CSV 文件。\")\n",
    "\n",
    "print(f\"找到 {len(file_paths)} 个CSV文件，开始加载...\")\n",
    "\n",
    "df_list = []\n",
    "for p in file_paths:\n",
    "    tmp = read_csv_force(p)\n",
    "    if tmp.empty:\n",
    "        print(f\"跳过空或损坏文件: {Path(p).name}\")\n",
    "        continue\n",
    "    cols = [c.lower() for c in tmp.columns]\n",
    "    q_col = next((c for c in tmp.columns if c.lower() in ['ask', 'question', 'query', '问题', '问']), None)\n",
    "    a_col = next((c for c in tmp.columns if c.lower() in ['answer', 'document', '答', '答案']), None)\n",
    "    dept_col = next((c for c in tmp.columns if c.lower() in ['department', '科室']), None)\n",
    "\n",
    "    if not q_col or not a_col:\n",
    "        print(f\"跳过文件 {Path(p).name}（未找到问答列）\")\n",
    "        continue\n",
    "    if not dept_col:\n",
    "        dept = Path(p).parent.name\n",
    "        tmp['department'] = dept\n",
    "    else:\n",
    "        tmp = tmp.rename(columns={dept_col: 'department'})\n",
    "\n",
    "    tmp = tmp.rename(columns={q_col: 'query', a_col: 'document'})\n",
    "    tmp = tmp.dropna(subset=['query', 'document', 'department'])\n",
    "    df_list.append(tmp[['query', 'document', 'department']])\n",
    "\n",
    "if not df_list:\n",
    "    raise RuntimeError(\"未成功加载任何有效问答文件。\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True).dropna(subset=['query', 'document'])\n",
    "print(f\"总计 {len(df):,} 条原始问答记录。\")\n",
    "\n",
    "# === 数据清洗 ===\n",
    "df = df[df['query'].str.len() > 5]\n",
    "df = df[df['document'].str.len() > 10]\n",
    "class_counts = df['department'].value_counts()\n",
    "classes_to_keep = class_counts[class_counts > 1].index\n",
    "df = df[df['department'].isin(classes_to_keep)]\n",
    "print(f\"数据清洗完成，剩余 {len(df):,} 条有效样本，{len(classes_to_keep)} 个科室。\")\n",
    "\n",
    "# === 分层抽样 ===\n",
    "_, test_df = train_test_split(\n",
    "    df, \n",
    "    test_size=TEST_SET_SIZE, \n",
    "    stratify=df['department'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"已通过分层抽样划分出 {len(test_df)} 条测试样本。\")\n",
    "\n",
    "# === 保存 ===\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILENAME), exist_ok=True)\n",
    "test_data = test_df[['query', 'document', 'department']].to_dict('records')\n",
    "with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"测试集已成功保存到: {OUTPUT_FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0153ee8-a9d4-41be-b5a2-05255f932cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/RAG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854f7f5-3379-4fd4-90a8-9fc9383d71a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
