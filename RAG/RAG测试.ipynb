{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f9041d-7a9b-4d60-89d7-b5d7c83ed3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/RAG'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5414ffbf-bf32-4f53-ad20-ce22b75f3d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === RAG: 基础配置 ===\n",
    "import os, json, math, pickle, gc\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 路径：请按你的实际情况修改\n",
    "BASE_MODEL_DIR    = \"/root/bert-base-chinese\"                       # 本地 BERT\n",
    "LORA_WEIGHT       = \"/root/models/model_best_stroke_lora.pth\"       # LoRA 权重\n",
    "MERGED_ENCODER    = \"/root/models/model_merged_stroke\"              # 若已合并，直接用\n",
    "QWEN_DIR          = \"/root/autodl-tmp/Qwen2.5-1.5B\"                 # 本地 Qwen 1.5B\n",
    "CORPUS_JSON       = \"/root/test_data_10k.json\"                      # 语料（{'query','document'}）\n",
    "RAG_DIR           = Path(\"/root/RAG\")\n",
    "RAG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INDEX_PATH        = RAG_DIR / \"faiss.index\"\n",
    "CHUNKS_META_PATH  = RAG_DIR / \"chunks.pkl\"\n",
    "\n",
    "# RAG 参数\n",
    "CHUNK_SIZE   = 250     # 每个 chunk 的中文字符数\n",
    "CHUNK_OVERLAP = 40     # 相邻 chunk 重叠\n",
    "TOP_K        = 5       # 检索返回条数\n",
    "BATCH_SIZE   = 64      # 编码 batch size\n",
    "MAX_LEN      = 128     # 编码最大长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3d52ed-cab2-4477-ac42-2203caee80b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder loaded (LoRA). Hidden: 768\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "def load_encoder():\n",
    "    # 优先加载合并后的编码器\n",
    "    if Path(MERGED_ENCODER).exists():\n",
    "        tok = AutoTokenizer.from_pretrained(MERGED_ENCODER, local_files_only=True)\n",
    "        enc = AutoModel.from_pretrained(MERGED_ENCODER, local_files_only=True).to(DEVICE).eval()\n",
    "        print(\"Encoder loaded (merged). Hidden:\", enc.config.hidden_size)\n",
    "        return tok, enc\n",
    "\n",
    "    # 否则按 LoRA 方式加载\n",
    "    tok = AutoTokenizer.from_pretrained(BASE_MODEL_DIR, local_files_only=True)\n",
    "    base = AutoModel.from_pretrained(BASE_MODEL_DIR, local_files_only=True)\n",
    "\n",
    "    # 与训练一致的 LoRA 配置\n",
    "    peft_cfg = LoraConfig(\n",
    "        r=8, lora_alpha=16, target_modules=[\"query\",\"key\",\"value\"],\n",
    "        lora_dropout=0.1, bias=\"none\"\n",
    "    )\n",
    "    enc = get_peft_model(base, peft_cfg)\n",
    "\n",
    "    # 加载权重（修正键名前缀）\n",
    "    sd = torch.load(LORA_WEIGHT, map_location=\"cpu\")\n",
    "    new_sd = { (k.replace(\"base_model.model.\",\"base_model.\") if k.startswith(\"base_model.model.\") else k): v\n",
    "               for k,v in sd.items() }\n",
    "    try:\n",
    "        enc.load_state_dict(new_sd, strict=True)\n",
    "    except Exception:\n",
    "        enc.load_state_dict(new_sd, strict=False)\n",
    "\n",
    "    enc = enc.to(DEVICE).eval()\n",
    "    print(\"Encoder loaded (LoRA). Hidden:\", enc.base_model.config.hidden_size if hasattr(enc,\"base_model\") else enc.config.hidden_size)\n",
    "    return tok, enc\n",
    "\n",
    "enc_tok, enc_model = load_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c587b06-64b7-4e83-96fe-154e378572c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready.\n"
     ]
    }
   ],
   "source": [
    "def load_llm():\n",
    "    llm_tok = AutoTokenizer.from_pretrained(QWEN_DIR, trust_remote_code=True, local_files_only=True)\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        QWEN_DIR, trust_remote_code=True, local_files_only=True\n",
    "    ).to(DEVICE).eval()\n",
    "    return llm_tok, llm\n",
    "\n",
    "llm_tok, llm = load_llm()\n",
    "print(\"LLM ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9532b9cb-6529-4eb2-98a3-b700e364417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded docs: 10000\n",
      "Total chunks: 11001\n"
     ]
    }
   ],
   "source": [
    "def load_corpus(json_path: str) -> List[Dict]:\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    # 兼容 [{'query','document'}] 或 [{'question','answer'}]\n",
    "    out = []\n",
    "    for r in data:\n",
    "        doc = r.get(\"document\") or r.get(\"answer\") or \"\"\n",
    "        q   = r.get(\"query\") or r.get(\"question\") or \"\"\n",
    "        if doc:\n",
    "            out.append({\"query\": q, \"document\": doc})\n",
    "    return out\n",
    "\n",
    "def chunk_text(text: str, size=CHUNK_SIZE, overlap=CHUNK_OVERLAP) -> List[str]:\n",
    "    text = text.strip().replace(\"\\n\", \"\")\n",
    "    if len(text) <= size:\n",
    "        return [text]\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + size\n",
    "        chunks.append(text[start:end])\n",
    "        if end >= len(text):\n",
    "            break\n",
    "        start = end - overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "    return chunks\n",
    "\n",
    "corpus = load_corpus(CORPUS_JSON)\n",
    "print(\"Loaded docs:\", len(corpus))\n",
    "\n",
    "# 构建 chunk 元信息\n",
    "chunks = []\n",
    "for i, r in enumerate(corpus):\n",
    "    for c in chunk_text(r[\"document\"], CHUNK_SIZE, CHUNK_OVERLAP):\n",
    "        chunks.append({\"doc_id\": i, \"text\": c})\n",
    "print(\"Total chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76220dc3-fb01-48b8-8d30-7f4831e8780c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 172/172 [00:12<00:00, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built: 11001 dim: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def encode_texts(texts: List[str]) -> torch.Tensor:\n",
    "    all_vecs = []\n",
    "    for i in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"Encoding\"):\n",
    "        batch = texts[i:i+BATCH_SIZE]\n",
    "        enc = enc_tok(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN)\n",
    "        enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "        out = enc_model(**enc, output_hidden_states=True)\n",
    "        cls = out.hidden_states[-1][:, 0, :]  # [CLS]\n",
    "        all_vecs.append(cls.detach().float().cpu())\n",
    "    return torch.cat(all_vecs, dim=0) if all_vecs else torch.empty(0, dtype=torch.float32)\n",
    "\n",
    "def build_or_load_index(chunks, index_path=INDEX_PATH, meta_path=CHUNKS_META_PATH):\n",
    "    if index_path.exists() and meta_path.exists():\n",
    "        index = faiss.read_index(str(index_path))\n",
    "        with open(meta_path, \"rb\") as f:\n",
    "            meta = pickle.load(f)\n",
    "        print(\"Index loaded:\", index.ntotal)\n",
    "        return index, meta\n",
    "\n",
    "    texts = [c[\"text\"] for c in chunks]\n",
    "    vecs = encode_texts(texts).numpy().astype(\"float32\")  # [N, D]\n",
    "    dim = vecs.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    # 向量先归一化，可用余弦相似度\n",
    "    faiss.normalize_L2(vecs)\n",
    "    index.add(vecs)\n",
    "\n",
    "    faiss.write_index(index, str(index_path))\n",
    "    with open(meta_path, \"wb\") as f:\n",
    "        pickle.dump(chunks, f)\n",
    "    print(\"Index built:\", index.ntotal, \"dim:\", dim)\n",
    "    return index, chunks\n",
    "\n",
    "index, chunks_meta = build_or_load_index(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a00d33e-cb0d-435f-af88-f9656893be76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve(query: str, top_k=TOP_K):\n",
    "    qv = encode_texts([query]).numpy().astype(\"float32\")\n",
    "    faiss.normalize_L2(qv)\n",
    "    D, I = index.search(qv, top_k)   # 余弦相似度\n",
    "    I = I[0].tolist()\n",
    "    D = D[0].tolist()\n",
    "    results = []\n",
    "    for idx, score in zip(I, D):\n",
    "        meta = chunks_meta[idx]\n",
    "        results.append({\"text\": meta[\"text\"], \"doc_id\": meta[\"doc_id\"], \"score\": float(score)})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec38cbb-89ac-408f-b20b-e0e1cf5efaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query: str, contexts: List[Dict]) -> str:\n",
    "    ctx = \"\\n\".join([f\"- {c['text']}\" for c in contexts])\n",
    "    prompt = (\n",
    "        \"你是医疗健康助手，请基于给定资料回答问题，确保内容准确、条理清晰，不要编造。\\n\"\n",
    "        f\"问题：{query}\\n\"\n",
    "        \"资料：\\n\"\n",
    "        f\"{ctx}\\n\"\n",
    "        \"回答：\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_answer(query: str, top_k=TOP_K, max_new_tokens=256):\n",
    "    ctxs = retrieve(query, top_k=top_k)\n",
    "    prompt = build_prompt(query, ctxs)\n",
    "\n",
    "    inputs = llm_tok(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    out = llm.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    ans = llm_tok.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # 简单截断，保留“回答：”之后内容\n",
    "    cut = ans.split(\"回答：\")\n",
    "    if len(cut) >= 2:\n",
    "        ans = cut[-1].strip()\n",
    "    return ans, ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cda64c-223b-4d6f-9a7a-8d84acc5d36a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1/1 [00:00<00:00, 45.01it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: 糖尿病患者早餐可以吃什么？\n",
      "Top1: 你好，孩子缺钙,要补钙和鱼肝油  ...\n",
      "A: 糖尿病患者早餐可以吃以下食物：\n",
      "1. 粗粮：如燕麦、糙米等，富含膳食纤维，有助于控制血糖。\n",
      "2. 蔬菜：如菠菜、西兰花、胡萝卜等，富含维生素和矿物质，有助于提高免疫力。\n",
      "3. 水果：如苹果、香蕉、橙子等，富含维生素C和纤维素，有助于降低血糖。\n",
      "4. 豆类：如黄豆、黑豆等，富含蛋白质和纤维素，有助于控制血糖。\n",
      "5. 鸡蛋：富含优质蛋白质和维生素，有助于提高免疫力。\n",
      "6. 牛奶：富含钙质和蛋白质，有助于提高免疫力。\n",
      "7. 鱼肉：富含优质蛋白质和不饱和脂肪酸，有助于降低血脂和血糖。\n",
      "8. 豆腐：富含蛋白质和钙质，有助于提高免疫力。\n",
      "9. 面包：富含碳水化合物和蛋白质，有助于提供能量。\n",
      "10. 馒头：富含碳水化合物和蛋白质，有助于提供能量。\n",
      "11. 面条：富含碳水化合物和蛋白质，有助于提供能量。\n",
      "12. 米饭：富含碳水化合物和蛋白质，有助于提供能量。\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1/1 [00:00<00:00, 67.14it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: 胃炎反复发作应该怎么调理？\n",
      "Top1: 请问我女儿两岁半了，现在发烧38.2度，可是不吃药，怎么办？38,2度是不是烧的很严重？怎么治疗？  ...\n",
      "A: 胃炎反复发作应该怎么调理？\n",
      "胃炎反复发作，建议您采取以下措施进行调理：\n",
      "\n",
      "1. **饮食调整**：避免辛辣、油腻、过热或过冷的食物，减少咖啡、酒精等刺激性饮品的摄入。选择易消化、营养丰富的食物，如粥、面条、蒸蛋等。\n",
      "\n",
      "2. **规律作息**：保持充足的睡眠，避免熬夜，有助于身体恢复。\n",
      "\n",
      "3. **减压放松**：长期的精神压力和紧张情绪可能加重胃炎症状，尝试通过运动、冥想、瑜伽等方式减轻压力。\n",
      "\n",
      "4. **药物治疗**：根据医生的指导使用抗酸药、胃黏膜保护剂等药物，以缓解症状和促进愈合。\n",
      "\n",
      "5. **定期复查**：定期到医院进行胃镜检查，监测病情变化，及时调整治疗方案。\n",
      "\n",
      "6. **生活方式改变**：戒烟限酒，避免过度劳累，保持良好的心态和生活习惯。\n",
      "\n",
      "7. **中医调理**：可以考虑采用中药调理，如服用具有健脾和胃作用的中药方剂，但需在专业中医师的指导下进行。\n",
      "\n",
      "请注意，以上建议仅供参考，\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1/1 [00:00<00:00, 59.31it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: 孕期贫血需要补充哪些营养？\n",
      "Top1: 你好，孩子缺钙,要补钙和鱼肝油  ...\n",
      "A: 孕期贫血需要补充哪些营养？\n",
      "孕期贫血是指孕妇在怀孕期间由于各种原因导致的贫血，需要补充的营养包括：\n",
      "\n",
      "1. 铁质：铁是制造血红蛋白的重要元素，可以补充铁质来提高血红蛋白水平，缓解贫血症状。\n",
      "\n",
      "2. 叶酸：叶酸是合成血红蛋白的重要原料，可以补充叶酸来提高血红蛋白水平，缓解贫血症状。\n",
      "\n",
      "3. 维生素B12：维生素B12是合成血红蛋白的重要原料，可以补充维生素B12来提高血红蛋白水平，缓解贫血症状。\n",
      "\n",
      "4. 钙质：钙质可以缓解贫血症状，可以补充钙质来提高血红蛋白水平，缓解贫血症状。\n",
      "\n",
      "5. 维生素C：维生素C可以促进铁的吸收，可以补充维生素C来提高铁的吸收率，缓解贫血症状。\n",
      "\n",
      "6. 维生素E：维生素E可以促进铁的吸收，可以补充维生素E来提高铁的吸收率，缓解贫血症状。\n",
      "\n",
      "7. 维生素D：维生素D可以促进钙的吸收，可以补充维生素D来提高钙的吸收率，缓解贫血症状。\n",
      "\n",
      "8. 维生素K：维生素K可以\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"糖尿病患者早餐可以吃什么？\",\n",
    "    \"胃炎反复发作应该怎么调理？\",\n",
    "    \"孕期贫血需要补充哪些营养？\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    ans, ctxs = generate_answer(q, top_k=5)\n",
    "    print(\"\\nQ:\", q)\n",
    "    print(\"Top1:\", ctxs[0][\"text\"][:120], \" ...\")\n",
    "    print(\"A:\", ans[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a7c879-5911-4db9-8981-f4e9558aada2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook RAG测试.ipynb to html\n",
      "[NbConvertApp] Writing 625427 bytes to RAG测试.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html RAG测试.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28395d3a-13bf-42a5-b626-149f90f1a34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
